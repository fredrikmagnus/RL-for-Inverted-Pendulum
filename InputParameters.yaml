run:
  type: train # train or test
  num_episodes: 1000 # Number of episodes to run
  episode_time: 25 # Maximum episode time in seconds
  dt: 0.025 # Time step in seconds
  batch_size: 16 # Mini-batch size for training

model:
  type: REINFORCE # DQN, REINFORCE or ActorCritic
  discount_factor: 0.99 # Discount factor for future rewards
  learning_rate: 1e-3 # Learning rate for the optimizer
  layer_sizes: [10, 10] # Number of neurons in each layer

  termination_penalty: -5 # Penalty for terminating the episode early

  init_from_weights: 
    enable: false # Initialize model from weights
    file_name: "AC.h5" # File name to load weights from
  save_weights:
    enable: true # Save weights to file
    file_name: "AC.h5" # File name to save weights to
    save_frequency: 2 # Save weights every n episodes

  DQN_params:
    epsilon_init: 1 # Initial epsilon value (for epsilon-greedy policy)
    epsilon_min: 0.1 # Minimum epsilon value
    epsilon_decay: 0.9 # Epsilon decay rate

pendulum_env:
  length: 1.0 # Length of the pendulum
  mass_base: 1.0 # Mass of the base
  mass_bob: 1.0 # Mass of the bob



  